{
    "version": "0.2.0",
    "configurations": [
      {
        "name": "Run VPTQ",
        "type": "python",
        "request": "launch",
        "justMyCode": false,
        "program": "${workspaceFolder}/run_vptq.py",
        "args": [
          // "--model_name", "weights/llama3-8b-hf",
          // "--output_dir", "outputs/llama3-8b-hf",
          // "--hessian_path", "weights/hessian/llama-31-8b",
          // "--inv_hessian_path", "weights/invhessian/llama-31-8b",

          "--model_name", "weights/Qwen2.5-7B-Instruct",
          "--output_dir", "outputs/Qwen2.5-7B-Instruct",
          "--hessian_path", "weights/hessian/qwen25-7b",
          "--inv_hessian_path", "weights/invhessian/qwen25-7b",
          
          "--vector_lens", "-1", "8",
          "--num_centroids", "-1", "65536",
          "--num_res_centroids", "-1", "256",

          // "--codebook_bitwidth","8",
          "--group_num", "1",
          "--npercent", "0",
          "--new_eval",
          "--seq_len", "8192",
          "--blocksize", "128",
          "--kmeans_mode", "hessian",
          "--gpu_ids", "1",
          "--enable_perm",
          "--enable_norm",
          "--save_model",
          "--save_packed_model",
          "--ktol", "1e-5",
          "--kiter", "100",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "6"},
        "console": "integratedTerminal"
      },
      {
        "name": "Run RPVQ",
        "type": "python",
        "request": "launch",
        "justMyCode": false,
        "program": "${workspaceFolder}/run_vptq.py",
        "args": [
          // "--model_name", "weights/llama3-8b-hf",
          // "--output_dir", "outputs/llama3-8b-hf",
          // "--hessian_path", "weights/hessian/llama-31-8b",
          // "--inv_hessian_path", "weights/invhessian/llama-31-8b",

          "--model_name", "weights/Qwen2.5-7B-Instruct",
          "--output_dir", "outputs/Qwen2.5-7B-Instruct",
          "--hessian_path", "weights/hessian/qwen25-7b",
          "--inv_hessian_path", "weights/invhessian/qwen25-7b",

          //rpvq的配置
          "--vector_lens", "-1",  "8","8","8","8",
          "--num_centroids", "-1",  "65536","256","64","64",
          "--num_res_centroids", "-1",  "16","16","16","16",
          "--npercent", "0", //outlier rate
          "--group_num", "4",
          "--vq_type","rpvq",
          // "--codebook_bitwidth","8",
          
          "--new_eval",
          "--seq_len", "8192",
          "--blocksize", "128",
          "--kmeans_mode", "hessian",
          "--enable_perm",
          "--enable_norm",
          // "--save_model",
          // "--save_packed_model",
          // "--save_qlinear",
          "--ktol", "1e-5",
          "--kiter", "100",
          "--gpu_ids", "4","4","4","4","4","4","4","5","5","5","5","5","5","5","6","6","6","6","6","6","6","1","1","1","1","1","1","1",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
        "console": "integratedTerminal"
      },
      {
        "name": "RPVQ_V1:分组",
        "type": "python",
        "request": "launch",
        "justMyCode": false,
        "program": "${workspaceFolder}/run_vptq.py",
        "args": [
          // "--model_name", "weights/llama3-8b-hf",
          // "--output_dir", "outputs/llama3-8b-hf",
          // "--hessian_path", "weights/hessian/llama-31-8b",
          // "--inv_hessian_path", "weights/invhessian/llama-31-8b",

          "--model_name", "weights/Qwen2.5-7B-Instruct",
          "--output_dir", "outputs/Qwen2.5-7B-Instruct",
          "--hessian_path", "weights/hessian/qwen25-7b",
          "--inv_hessian_path", "weights/invhessian/qwen25-7b",

          //rpvq的配置
          "--vector_lens", "-1",  "4","4","8","8",
          "--num_centroids", "-1",  "65536","4096","65536","256",
          "--num_res_centroids", "-1",  "-1","-1","-1","-1",
          "--npercent", "0", //outlier rate
          "--group_num", "4",
          "--vq_type","rpvq_v1",
          // "--codebook_bitwidth","8",
          
          "--new_eval",
          "--seq_len", "8192",
          "--blocksize", "128",
          "--kmeans_mode", "hessian",
          "--enable_perm",
          "--enable_norm",
          // "--save_model",
          // "--save_packed_model",
          // "--save_qlinear",
          "--ktol", "1e-5",
          "--kiter", "100",
          "--gpu_ids", "4","4","4","4","4","4","4","5","5","5","5","5","5","5","6","6","6","6","6","6","6","7","7","7","7","7","7","7",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "4,5,6,7"},
        "console": "integratedTerminal"
      },
      {
        "name": "RPVQ_V2:分组残差金字塔",
        "type": "python",
        "request": "launch",
        "justMyCode": false,
        "program": "${workspaceFolder}/run_vptq.py",
        "args": [
          // "--model_name", "weights/llama3-8b-hf",
          // "--output_dir", "outputs/llama3-8b-hf",
          // "--hessian_path", "weights/hessian/llama-31-8b",
          // "--inv_hessian_path", "weights/invhessian/llama-31-8b",

          "--model_name", "weights/Qwen2.5-7B-Instruct",
          "--output_dir", "outputs/Qwen2.5-7B-Instruct",
          "--hessian_path", "weights/hessian/qwen25-7b",
          "--inv_hessian_path", "weights/invhessian/qwen25-7b",

          //rpvq的配置
          "--vector_lens", "-1",        "4",  "4",  "4",  "8",
          "--num_centroids", "-1",      "65536","4096","256","256",
          "--num_res_centroids", "-1",  "-1", "-1", "-1", "-1",
          "--num_res_layers", "-1",     "1",  "1",  "1",  "1",
          "--npercent", "0", //outlier rate
          "--group_num", "4",
          "--vq_type","rpvq_v2",
          
          "--new_eval",
          "--seq_len", "8192",
          "--blocksize", "128",
          "--kmeans_mode", "hessian",
          "--enable_perm",
          "--enable_norm",
          "--ktol", "1e-5",
          "--kiter", "100",
          "--gpu_ids", "3","3","3","3","3","3","3",//"4","4","4","4","4","4","4","5","5","5","5","5","5","5","6","6","6","6","6","6","6",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "3"},
        "console": "integratedTerminal"
      },
      {
        "name": "RPVQ_V3:分组PQ",
        "type": "python",
        "request": "launch",
        "justMyCode": false,
        "program": "${workspaceFolder}/run_rpvq.py",
        "args": [
          "--model_name", "weights/llama3-8b-hf",
          "--output_dir", "outputs/llama3-8b-hf",
          "--hessian_path", "weights/hessian/llama-31-8b",
          "--inv_hessian_path", "weights/invhessian/llama-31-8b",

          // "--model_name", "weights/Qwen2.5-7B-Instruct",
          // "--output_dir", "outputs/Qwen2.5-7B-Instruct",
          // "--hessian_path", "weights/hessian/qwen25-7b",
          // "--inv_hessian_path", "weights/invhessian/qwen25-7b",

          //rpvq的配置
          "--vector_lens", "-1",        "6", // "6",  "6",  "6",
          "--num_centroids", "-1",      "384",//"512","256","256",
          "--num_res_layers", "-1",     "2",  //"2",  "2",  "2",
          "--num_res_centroids", "-1",  "-1", //"-1", "-1", "-1",
          "--group_num", "1",
          "--low_rank","64", //按照4096的比例折算。0.25bit
          "--low_rank_hessian","True",
          "--gptq","True",
          "--npercent", "0", //outlier rate

          "--vq_type","finetune",//finetune  rpvq_v3
          "--finetune_type","e2e",// block_codebook_lowrank block_codebook  block_lowrank e2e
          "--train_dataset","wikitext2",
          "--batch_size","4",
          "--devset_size","141",
          "--ctx_size","2048",
          "--ft_valid_size","5",
          "--ft_valid_freq","1",
          "--ft_bs","2",
          "--ft_lr","5e-4",
          "--ft_epochs","2",
          "--ft_early_stop","2",
          "--ft_loss_type","kl", //kl  mse
          "--finetune_blocks","0",//"31",//"30","29","28","27","26","25","24",
          
          "--new_eval",
          "--seq_len", "2048",
          "--blocksize", "128",
          "--kmeans_mode", "hessian",
          "--enable_perm",
          "--enable_norm",
          "--ktol", "1e-5",
          "--kiter", "100",
          "--gpu_ids", "6",//"6","6","6","6","6","6","5","5","5","5","5","5","5","1","1","1","1","1","1","1","4","4","4","4","4","4","4","2","2","2","2",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "6"},
        "console": "integratedTerminal"
      },
      {
        "name": "infer",
        "type": "python",
        "request": "launch",
        "program": "${workspaceFolder}/run_vptq_pakedmodel.py",
        "cwd": "${workspaceFolder}/",
        "justMyCode": false,
        "args": [
          "--model_name", "weights/Qwen2.5-7B-Instruct",
          "--packed_model","outputs/Qwen2.5-7B-Instruct/2024-12-24-10-10-43/packed_model",
          "--prompt","Explain: Do Not Go Gentle into That Good Night",
          "--chat",
        ],
        "env": {"CUDA_VISIBLE_DEVICES": "7"},
        "console": "integratedTerminal"
      },
    ]
}
  